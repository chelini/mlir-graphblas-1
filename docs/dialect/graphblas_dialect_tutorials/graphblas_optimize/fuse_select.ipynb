{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ea7794",
   "metadata": {},
   "source": [
    "# Fusion of graphblas.matrix_select Ops\n",
    "\n",
    "This example will go over how to use the `--graphblas-optimize` pass from `graphblas-opt` to fuse `graphblas.matrix_select` ops.\n",
    "\n",
    "When fusing `graphblas.matrix_select` ops, `--graphblas-optimize` simply combines several sequential `graphblas.matrix_select` ops into a single use of `graphblas.matrix_select` with multiple `selector` attributes.\n",
    "\n",
    "Let's first import some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dfc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from mlir_graphblas.cli import GRAPHBLAS_OPT_EXE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef189e",
   "metadata": {},
   "source": [
    "Since [sparse tensor encodings](https://mlir.llvm.org/docs/Dialects/SparseTensorOps/#sparsetensorencodingattr) can be very verbose in MLIR, let's write some helpers to make the MLIR code more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4233b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tersify_mlir(input_string: str) -> str:\n",
    "    terse_string = input_string\n",
    "    terse_string = terse_string.replace(\n",
    "        '''#sparse_tensor.encoding<{ '''\n",
    "        '''dimLevelType = [ \"dense\", \"compressed\" ], '''\n",
    "        '''dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, '''\n",
    "        '''pointerBitWidth = 64, '''\n",
    "        '''indexBitWidth = 64 '''\n",
    "        '''}>''', \n",
    "        \"#CSR64\")\n",
    "    terse_string = terse_string.replace(\n",
    "        '''#sparse_tensor.encoding<{ '''\n",
    "        '''dimLevelType = [ \"dense\", \"compressed\" ], '''\n",
    "        '''dimOrdering = affine_map<(d0, d1) -> (d1, d0)>, '''\n",
    "        '''pointerBitWidth = 64, '''\n",
    "        '''indexBitWidth = 64 '''\n",
    "        '''}>''', \n",
    "        \"#CSC64\")\n",
    "    return terse_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db75a69",
   "metadata": {},
   "source": [
    "## Fusing Single Selector graphblas.matrix_select Ops\n",
    "\n",
    "If we have several uses of `graphblas.matrix_select` each specifying a single selector, then `--graphblas-optimize` fuses them into one call with many selectors.\n",
    "\n",
    "Here's some example code using several sequential `graphblas.matrix_select` ops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a6fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @select_fuse_single(%sparse_tensor: tensor<?x?xf64, #CSR64>) -> (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>) {\n",
    "    %answer1 = graphblas.matrix_select %sparse_tensor { selectors = [\"gt0\"] } : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>\n",
    "    %answer2 = graphblas.matrix_select %sparse_tensor { selectors = [\"triu\"] } : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>\n",
    "    %answer3 = graphblas.matrix_select %sparse_tensor { selectors = [\"tril\"] } : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>\n",
    "    return %answer1, %answer2, %answer3 : tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db32140",
   "metadata": {},
   "source": [
    "Let's see what code we get when we run it through `graphblas-opt` with the `--graphblas-optimize` pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54ca16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp_file_name = temp.name\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        f.write(mlir_text)\n",
    "    temp.flush()\n",
    "\n",
    "    output_mlir = ! cat $temp_file_name | $GRAPHBLAS_OPT_EXE --graphblas-optimize\n",
    "    output_mlir = \"\\n\".join(output_mlir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d3c76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module  {\n",
      "  func @select_fuse_single(%arg0: tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>) -> (tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>, tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>, tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>) {\n",
      "    %0:3 = graphblas.matrix_select %arg0 {selectors = [\"tril\", \"triu\", \"gt0\"]} : tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>> to tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>, tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>, tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>\n",
      "    return %0#2, %0#1, %0#0 : tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>, tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>, tensor<?x?xf64, #sparse_tensor.encoding<{ dimLevelType = [ \"dense\", \"compressed\" ], dimOrdering = affine_map<(d0, d1) -> (d0, d1)>, pointerBitWidth = 64, indexBitWidth = 64 }>>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ca5d1",
   "metadata": {},
   "source": [
    "This is difficult to read due to the verbosity of the sparse tensor encodings. Let's make it more terse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ba8f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module  {\n",
      "  func @select_fuse_single(%arg0: tensor<?x?xf64, #CSR64>) -> (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>) {\n",
      "    %0:3 = graphblas.matrix_select %arg0 {selectors = [\"tril\", \"triu\", \"gt0\"]} : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
      "    return %0#2, %0#1, %0#0 : tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_mlir = tersify_mlir(output_mlir)\n",
    "print(output_mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c42da",
   "metadata": {},
   "source": [
    "As shown above, `--graphblas-optimize` combined the original 3 uses of `graphblas.matrix_select` into one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3510cff0",
   "metadata": {},
   "source": [
    "## Fusing Single Selector or Multi-Selector graphblas.matrix_select Ops\n",
    "\n",
    "`--graphblas-optimize` also fuses calls of `graphblas.matrix_select` that contain multiple selectors as shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff2d2506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module  {\n",
      "  func @select_fuse_multi(%arg0: tensor<?x?xf64, #CSR64>) -> (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>) {\n",
      "    %0:3 = graphblas.matrix_select %arg0 {selectors = [\"tril\", \"gt0\", \"triu\"]} : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
      "    return %0#1, %0#2, %0#0 : tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @select_fuse_multi(%sparse_tensor: tensor<?x?xf64, #CSR64>) -> (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>) {\n",
    "    %answer1, %answer2 = graphblas.matrix_select %sparse_tensor { selectors = [\"gt0\", \"triu\"] } : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
    "    %answer3 = graphblas.matrix_select %sparse_tensor { selectors = [\"tril\"] } : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>\n",
    "    return %answer1, %answer2, %answer3 : tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
    "}\n",
    "\"\"\"\n",
    "with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp_file_name = temp.name\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        f.write(mlir_text)\n",
    "    temp.flush()\n",
    "\n",
    "    output_mlir = ! cat $temp_file_name | $GRAPHBLAS_OPT_EXE --graphblas-optimize\n",
    "    output_mlir = \"\\n\".join(output_mlir)\n",
    "    output_mlir = tersify_mlir(output_mlir)\n",
    "\n",
    "print(output_mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca92f7",
   "metadata": {},
   "source": [
    "## Fusing graphblas.matrix_select Ops With Different Source Tensors\n",
    "\n",
    "Our previous examples fused tensors that all selected from the same source tensor. \n",
    "\n",
    "`--graphblas-optimize` can also fuse calls that use different source tensors as shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f57179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module  {\n",
      "  func @select_fuse_separate(%arg0: tensor<?x?xf64, #CSR64>, %arg1: tensor<?x?xf64, #CSR64>) -> (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>) {\n",
      "    %0 = graphblas.matrix_select %arg1 {selectors = [\"triu\"]} : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>\n",
      "    %1:2 = graphblas.matrix_select %arg0 {selectors = [\"tril\", \"gt0\"]} : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
      "    return %1#1, %0, %1#0 : tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @select_fuse_separate(%sparse_tensor1: tensor<?x?xf64, #CSR64>, %sparse_tensor2: tensor<?x?xf64, #CSR64>) -> (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>) {\n",
    "    %answer1 = graphblas.matrix_select %sparse_tensor1 { selectors = [\"gt0\"] } : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>\n",
    "    %answer2 = graphblas.matrix_select %sparse_tensor2 { selectors = [\"triu\"] } : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>\n",
    "    %answer3 = graphblas.matrix_select %sparse_tensor1 { selectors = [\"tril\"] } : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSR64>\n",
    "    return %answer1, %answer2, %answer3 : tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSR64>\n",
    "}\n",
    "\"\"\"\n",
    "with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp_file_name = temp.name\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        f.write(mlir_text)\n",
    "    temp.flush()\n",
    "\n",
    "    output_mlir = ! cat $temp_file_name | $GRAPHBLAS_OPT_EXE --graphblas-optimize\n",
    "    output_mlir = \"\\n\".join(output_mlir)\n",
    "    output_mlir = tersify_mlir(output_mlir)\n",
    "\n",
    "print(output_mlir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095435c7",
   "metadata": {},
   "source": [
    "Note that this necessarily reduces to two `graphblas.matrix_select` uses since `graphblas.matrix_select` takes exactly 1 source tensor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
