{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df94aea",
   "metadata": {},
   "source": [
    "# graphblas.matrix_multiply\n",
    "\n",
    "This example will go over how to use the `--graphblas-lower` pass from `graphblas-opt` to lower the `graphblas.matrix_multiply` op.\n",
    "\n",
    "Letâ€™s first import some necessary modules and generate an instance of our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a93b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir_graphblas\n",
    "import mlir_graphblas.sparse_utils\n",
    "import numpy as np\n",
    "\n",
    "engine = mlir_graphblas.MlirJitEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251bd4a",
   "metadata": {},
   "source": [
    "Here are the passes we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5430c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--graphblas-lower\",\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--tensor-constant-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-scf-to-std\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c57dde",
   "metadata": {},
   "source": [
    "Similar to our examples using the GraphBLAS dialect, we'll need some helper functions to convert sparse tensors to dense tensors. \n",
    "\n",
    "We'll also need some helpers to convert our sparse matrices to CSC format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21e453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_densify_csr = {\n",
    "  indexing_maps = [\n",
    "    affine_map<(i,j) -> (i,j)>,\n",
    "    affine_map<(i,j) -> (i,j)>\n",
    "  ],\n",
    "  iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @csr_densify4x4(%argA: tensor<4x4xf64, #CSR64>) -> tensor<4x4xf64> {\n",
    "  %output_storage = constant dense<0.0> : tensor<4x4xf64>\n",
    "  %0 = linalg.generic #trait_densify_csr\n",
    "    ins(%argA: tensor<4x4xf64, #CSR64>)\n",
    "    outs(%output_storage: tensor<4x4xf64>) {\n",
    "      ^bb(%A: f64, %x: f64):\n",
    "        linalg.yield %A : f64\n",
    "    } -> tensor<4x4xf64>\n",
    "  return %0 : tensor<4x4xf64>\n",
    "}\n",
    "\n",
    "#trait_densify_csc = {\n",
    "  indexing_maps = [\n",
    "    affine_map<(i,j) -> (j,i)>,\n",
    "    affine_map<(i,j) -> (i,j)>\n",
    "  ],\n",
    "  iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @csc_densify4x4(%argA: tensor<4x4xf64, #CSC64>) -> tensor<4x4xf64> {\n",
    "  %output_storage = constant dense<0.0> : tensor<4x4xf64>\n",
    "  %0 = linalg.generic #trait_densify_csc\n",
    "    ins(%argA: tensor<4x4xf64, #CSC64>)\n",
    "    outs(%output_storage: tensor<4x4xf64>) {\n",
    "      ^bb(%A: f64, %x: f64):\n",
    "        linalg.yield %A : f64\n",
    "    } -> tensor<4x4xf64>\n",
    "  return %0 : tensor<4x4xf64>\n",
    "}\n",
    "\n",
    "func @convert_csr_to_csc(%sparse_tensor: tensor<?x?xf64, #CSR64>) -> tensor<?x?xf64, #CSC64> {\n",
    "    %answer = graphblas.convert_layout %sparse_tensor : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSC64>\n",
    "    return %answer : tensor<?x?xf64, #CSC64>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9665db",
   "metadata": {},
   "source": [
    "Let's compile our MLIR code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5aff980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csr_densify4x4', 'csc_densify4x4', 'convert_csr_to_csc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71ba14",
   "metadata": {},
   "source": [
    "## Overview of graphblas.matrix_multiply\n",
    "\n",
    "Here, we'll show how to use the `graphblas.matrix_multiply` op. \n",
    "\n",
    "`graphblas.matrix_multiply` takes a sparse matrix operand in CSR format, a sparse matrix operand in CSC format, and a `semiring` attribute. \n",
    "\n",
    "The single `semiring` attribute indicates an element-wise operator and an aggregation operator. For example, the plus-times semiring indicates an element-wise operator of multiplication and an aggregation operator of addition/summation. For more details about semirings, see [here](https://en.wikipedia.org/wiki/GraphBLAS).\n",
    "\n",
    "`graphblas.matrix_multiply` applies the semiring's element-wise operator and aggregation operator in matrix-multiply order over the two given sparse matrices. For example, using `graphblas.matrix_multiply` with the plus-times semiring will get a matrix that is the result of a conventional matrix multiply.\n",
    "\n",
    "\n",
    "Here's an example use of the `graphblas.matrix_multiply` op:\n",
    "```\n",
    "%answer = graphblas.matrix_multiply %argA, %argB, %mask { semiring = \"plus_times\" } : (tensor<2x2xf64, #CSR64>, tensor<2x2xf64, #CSC64>, tensor<2x2xf64, #CSR64>) to tensor<2x2xf64, #CSR64>\n",
    "```\n",
    "\n",
    "The supported options for the `semiring` attribute are \"plus_pair\", \"plus_plus\", and \"plus_times\".\n",
    "\n",
    "`graphblas.matrix_multiply` can also take an optional mask operand (a CSR matrix) as shown in this example:\n",
    "```\n",
    "%answer = graphblas.matrix_multiply %argA, %argB, %mask { semiring = \"plus_times\" } : (tensor<2x3xf64, #CSR64>, tensor<3x2xf64, #CSC64>, tensor<2x2xf64, #CSR64>) to tensor<2x2xf64, #CSR64>\n",
    "```\n",
    "\n",
    "The mask operand must have the same shape as the output matrix. The mask operand acts as a boolean mask (though doesn't necessarily have to have a boolean element type) for the result, which increases performance since the mask will indicate which values in the output do not have to be calculated.\n",
    "\n",
    "`graphblas.matrix_multiply` can also take an optional [region](https://mlir.llvm.org/docs/LangRef/#regions) as shown in this example:\n",
    "```\n",
    "%cf4 = constant 4.0 : f64\n",
    "%answer = graphblas.matrix_multiply %argA, %argB { semiring = \"plus_times\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64> {\n",
    "        ^bb0(%value: f64):\n",
    "            %result = std.addf %value, %cf4: f64\n",
    "            graphblas.yield %result : f64\n",
    "    }\n",
    "```\n",
    "The NumPy equivalent of this code would be `answer = (argA @ argB) + 4.0`.\n",
    "\n",
    "The region specifies element-wise post-processing done on values that survived the masking (applies to all elements if no mask). We'll go into deeper details later on on how to write a region using `graphblas.yield`. \n",
    "\n",
    "Let's create some example input matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d263eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(\n",
    "    [\n",
    "        [0, 3],\n",
    "        [1, 3],\n",
    "        [2, 0],\n",
    "        [3, 0],\n",
    "        [3, 1],\n",
    "    ],\n",
    "    dtype=np.uint64,\n",
    ")\n",
    "values = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    "sizes = np.array([4, 4], dtype=np.uint64)\n",
    "sparsity = np.array([False, True], dtype=np.bool8)\n",
    "\n",
    "A = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6242a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [0, 3],\n",
    "        [1, 1],\n",
    "        [1, 3],\n",
    "        [2, 0],\n",
    "        [2, 2],\n",
    "        [3, 0],\n",
    "        [3, 2],\n",
    "    ],\n",
    "    dtype=np.uint64,\n",
    ")\n",
    "values = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float64)\n",
    "sizes = np.array([4, 4], dtype=np.uint64)\n",
    "sparsity = np.array([False, True], dtype=np.bool8)\n",
    "\n",
    "B_csr = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)\n",
    "B = engine.convert_csr_to_csc(B_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "849c050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [0, 2],\n",
    "        [1, 1],\n",
    "        [1, 2],\n",
    "        [2, 1],\n",
    "        [2, 2],\n",
    "        [3, 1],\n",
    "        [3, 2],\n",
    "    ],\n",
    "    dtype=np.uint64,\n",
    ")\n",
    "values = np.array([-0.1, 0.2, -0.3, 0.4, -0.5, 0.6, -0.7, 0.8], dtype=np.float64)\n",
    "sizes = np.array([4, 4], dtype=np.uint64)\n",
    "sparsity = np.array([False, True], dtype=np.bool8)\n",
    "\n",
    "mask = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea20554",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dense = engine.csr_densify4x4(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c190a36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 2.],\n",
       "       [3., 0., 0., 0.],\n",
       "       [4., 5., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0169161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_dense = engine.csc_densify4x4(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df49b6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 2.],\n",
       "       [0., 3., 0., 4.],\n",
       "       [5., 0., 6., 0.],\n",
       "       [7., 0., 8., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e25ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dense = engine.csr_densify4x4(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08a016c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. , -0.1,  0.2,  0. ],\n",
       "       [ 0. , -0.3,  0.4,  0. ],\n",
       "       [ 0. , -0.5,  0.6,  0. ],\n",
       "       [ 0. , -0.7,  0.8,  0. ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cf346",
   "metadata": {},
   "source": [
    "## graphblas.matrix_multiply (Plus-Times Semiring)\n",
    "\n",
    "Here, we'll simply perform a conventional matrix-multiply by using `graphblas.matrix_multiply` with the plus-times semiring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cac3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "module {\n",
    "    func @matrix_multiply_plus_times(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>) -> tensor<?x?xf64, #CSR64> {\n",
    "        %answer = graphblas.matrix_multiply %a, %b { semiring = \"plus_times\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64>\n",
    "        return %answer : tensor<?x?xf64, #CSR64>\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee1ec541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix_multiply_plus_times']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "894e1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matmul_result = engine.matrix_multiply_plus_times(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccdba414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0.,  8.,  0.],\n",
       "       [14.,  0., 16.,  0.],\n",
       "       [ 0.,  3.,  0.,  6.],\n",
       "       [ 0., 19.,  0., 28.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.csr_densify4x4(sparse_matmul_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a426c47",
   "metadata": {},
   "source": [
    "The result looks sane. Let's verify that it has the same behavior as NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b9516b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(A_dense @ B_dense == engine.csr_densify4x4(sparse_matmul_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48677164",
   "metadata": {},
   "source": [
    "## graphblas.matrix_multiply (Plus-Plus Semiring with Mask)\n",
    "\n",
    "Here, we'll perform a matrix-multiply with the plus-plus semiring. We'll show the result with and without a mask to demonstrate how the masking works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e21383c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "module {\n",
    "    func @matrix_multiply_plus_plus_no_mask(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>) -> tensor<?x?xf64, #CSR64> {\n",
    "        %answer = graphblas.matrix_multiply %a, %b { semiring = \"plus_plus\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64>\n",
    "        return %answer : tensor<?x?xf64, #CSR64>\n",
    "    }\n",
    "    \n",
    "    func @matrix_multiply_plus_plus(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>, %m: tensor<?x?xf64, #CSR64>) -> tensor<?x?xf64, #CSR64> {\n",
    "        %answer = graphblas.matrix_multiply %a, %b, %m { semiring = \"plus_plus\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>, tensor<?x?xf64, #CSR64>) to tensor<?x?xf64, #CSR64>\n",
    "        return %answer : tensor<?x?xf64, #CSR64>\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ba6bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix_multiply_plus_plus_no_mask', 'matrix_multiply_plus_plus']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e83a5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_mask_result = engine.matrix_multiply_plus_plus_no_mask(A, B)\n",
    "with_mask_result = engine.matrix_multiply_plus_plus(A, B, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c9b0dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.,  0.,  9.,  0.],\n",
       "       [ 9.,  0., 10.,  0.],\n",
       "       [ 0.,  4.,  0.,  5.],\n",
       "       [ 0., 13.,  0., 15.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.csr_densify4x4(no_mask_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69451c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  9.,  0.],\n",
       "       [ 0.,  0., 10.,  0.],\n",
       "       [ 0.,  4.,  0.,  0.],\n",
       "       [ 0., 13.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.csr_densify4x4(with_mask_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83638bad",
   "metadata": {},
   "source": [
    "Note how the results in the masked output only have elements present in the positions where the mask had elements present. \n",
    "\n",
    "Since we can't verify the results via NumPy given that it doesn't support semirings in its matrix multiply implementation, we'll leave the task of verifying the results as an exercise for the reader. Note that if we're applying the element-wise operation to the values at two positions (one each sparse tensor) and one position has a value but not the other does not, then the element-wise operation for these two positions will contribute no value to be aggregated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df20a35",
   "metadata": {},
   "source": [
    "## graphblas.matrix_multiply (Plus-Pair Semiring with Region)\n",
    "\n",
    "Here, we'll perform a matrix-multiply with the plus-pair semiring. We'll show the result without using a region and with a region. \n",
    "\n",
    "The element-wise operation of the plus-pair semiring is defined as `pair(x, y) = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7a8bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "module {\n",
    "    func @matrix_multiply_plus_pair_no_region(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>) -> tensor<?x?xf64, #CSR64> {\n",
    "        %answer = graphblas.matrix_multiply %a, %b { semiring = \"plus_pair\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64>\n",
    "        return %answer : tensor<?x?xf64, #CSR64>\n",
    "    }\n",
    "    \n",
    "    func @matrix_multiply_plus_pair_and_square(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>) -> tensor<?x?xf64, #CSR64> {\n",
    "        %answer = graphblas.matrix_multiply %a, %b { semiring = \"plus_pair\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64> {\n",
    "            ^bb0(%value: f64):\n",
    "                %result = std.mulf %value, %value: f64\n",
    "                graphblas.yield %result : f64\n",
    "        }\n",
    "        return %answer : tensor<?x?xf64, #CSR64>\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dd7c15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix_multiply_plus_pair_no_region', 'matrix_multiply_plus_pair_and_square']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a923255",
   "metadata": {},
   "source": [
    "The code in the region of `matrix_multiply_plus_pair_and_square` simply squares each individual element's value. The use of `graphblas.yield` is used here to indicate the result of each element-wise squaring.\n",
    "\n",
    "Let's first get our results without the region. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48605be2",
   "metadata": {},
   "source": [
    "`matrix_multiply_plus_pair_no_region` simply does a matrix multiply with the plus-pair semiring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f42b9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_region_result = engine.matrix_multiply_plus_pair_no_region(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cebe8030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 2., 0., 2.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.csr_densify4x4(no_region_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f12a5a",
   "metadata": {},
   "source": [
    "Let's now get the results from `matrix_multiply_plus_pair_and_square`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "249864af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_region_result = engine.matrix_multiply_plus_pair_and_square(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cb67df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 4., 0., 4.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.csr_densify4x4(with_region_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268645a3",
   "metadata": {},
   "source": [
    "Let's verify that our results are sane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5983a962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(engine.csr_densify4x4(with_region_result) == engine.csr_densify4x4(no_region_result)**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
