{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e37bc79",
   "metadata": {},
   "source": [
    "# graphblas.matrix_multiply_reduce_to_scalar\n",
    "\n",
    "This example will go over how to compile MLIR code (using the GraphBLAS dialect) to a function callable from Python.\n",
    "\n",
    "The example MLIR code we’ll use here will demonstrate how the `graphblas.matrix_multiply_reduce_to_scalar` op from the GraphBLAS dialect works. \n",
    "\n",
    "Let’s first import some necessary modules and generate an instance of our JIT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e07aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir_graphblas\n",
    "import mlir_graphblas.sparse_utils\n",
    "import numpy as np\n",
    "\n",
    "engine = mlir_graphblas.MlirJitEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ec81a",
   "metadata": {},
   "source": [
    "Here are the passes we'll use. The pass `--graphblas-lower` is necessary to lower the GraphBLAS dialect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e90887",
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = [\n",
    "    \"--graphblas-lower\",\n",
    "    \"--sparsification\",\n",
    "    \"--sparse-tensor-conversion\",\n",
    "    \"--linalg-bufferize\",\n",
    "    \"--func-bufferize\",\n",
    "    \"--tensor-bufferize\",\n",
    "    \"--tensor-constant-bufferize\",\n",
    "    \"--finalizing-bufferize\",\n",
    "    \"--convert-linalg-to-loops\",\n",
    "    \"--convert-scf-to-std\",\n",
    "    \"--convert-std-to-llvm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c57dde",
   "metadata": {},
   "source": [
    "Similar to our examples using the GraphBLAS dialect, we'll need some helper functions to convert sparse tensors to dense tensors. \n",
    "\n",
    "We'll also need some helpers to convert our sparse matrices to CSC format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21e453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#trait_densify_csr = {\n",
    "  indexing_maps = [\n",
    "    affine_map<(i,j) -> (i,j)>,\n",
    "    affine_map<(i,j) -> (i,j)>\n",
    "  ],\n",
    "  iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @csr_densify4x4(%argA: tensor<4x4xf64, #CSR64>) -> tensor<4x4xf64> {\n",
    "  %output_storage = constant dense<0.0> : tensor<4x4xf64>\n",
    "  %0 = linalg.generic #trait_densify_csr\n",
    "    ins(%argA: tensor<4x4xf64, #CSR64>)\n",
    "    outs(%output_storage: tensor<4x4xf64>) {\n",
    "      ^bb(%A: f64, %x: f64):\n",
    "        linalg.yield %A : f64\n",
    "    } -> tensor<4x4xf64>\n",
    "  return %0 : tensor<4x4xf64>\n",
    "}\n",
    "\n",
    "#trait_densify_csc = {\n",
    "  indexing_maps = [\n",
    "    affine_map<(i,j) -> (j,i)>,\n",
    "    affine_map<(i,j) -> (i,j)>\n",
    "  ],\n",
    "  iterator_types = [\"parallel\", \"parallel\"]\n",
    "}\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "func @csc_densify4x4(%argA: tensor<4x4xf64, #CSC64>) -> tensor<4x4xf64> {\n",
    "  %output_storage = constant dense<0.0> : tensor<4x4xf64>\n",
    "  %0 = linalg.generic #trait_densify_csc\n",
    "    ins(%argA: tensor<4x4xf64, #CSC64>)\n",
    "    outs(%output_storage: tensor<4x4xf64>) {\n",
    "      ^bb(%A: f64, %x: f64):\n",
    "        linalg.yield %A : f64\n",
    "    } -> tensor<4x4xf64>\n",
    "  return %0 : tensor<4x4xf64>\n",
    "}\n",
    "\n",
    "func @convert_csr_to_csc(%sparse_tensor: tensor<?x?xf64, #CSR64>) -> tensor<?x?xf64, #CSC64> {\n",
    "    %answer = graphblas.convert_layout %sparse_tensor : tensor<?x?xf64, #CSR64> to tensor<?x?xf64, #CSC64>\n",
    "    return %answer : tensor<?x?xf64, #CSC64>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9665db",
   "metadata": {},
   "source": [
    "Let's compile our MLIR code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5aff980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csr_densify4x4', 'csc_densify4x4', 'convert_csr_to_csc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d6717",
   "metadata": {},
   "source": [
    "## Overview of graphblas.matrix_multiply_reduce_to_scalar\n",
    "\n",
    "Here, we'll show how to use the `graphblas.matrix_multiply_reduce_to_scalar` op. \n",
    "\n",
    "`graphblas.matrix_multiply_reduce_to_scalar` is behaviorally equivalent to sequential calls to `graphblas.matrix_multiply` and `graphblas.matrix_reduce_to_scalar`. The. purpose of `graphblas.matrix_multiply_reduce_to_scalar` is to allow the lowering to add additional performance optimizations that wouldn't be available when using `graphblas.matrix_multiply` and `graphblas.matrix_reduce_to_scalar` independently.\n",
    "\n",
    "Here's an example use of the `graphblas.matrix_multiply_reduce_to_scalar` op:\n",
    "```\n",
    "%answer = graphblas.matrix_multiply_reduce_to_scalar %a, %b { semiring = \"plus_times\", aggregator = \"sum\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to f64\n",
    "```\n",
    "\n",
    "The options for the `semiring` and `aggregator` attributes are the same as those for `graphblas.matrix_multiply` and `graphblas.matrix_reduce_to_scalar`, respectively.\n",
    "\n",
    "Let's create some example sparse input matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d263eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(\n",
    "    [\n",
    "        [0, 3],\n",
    "        [1, 3],\n",
    "        [2, 0],\n",
    "        [3, 0],\n",
    "        [3, 1],\n",
    "    ],\n",
    "    dtype=np.uint64,\n",
    ")\n",
    "values = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    "sizes = np.array([4, 4], dtype=np.uint64)\n",
    "sparsity = np.array([False, True], dtype=np.bool8)\n",
    "\n",
    "A = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6242a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [0, 3],\n",
    "        [1, 1],\n",
    "        [1, 3],\n",
    "        [2, 0],\n",
    "        [2, 2],\n",
    "        [3, 0],\n",
    "        [3, 2],\n",
    "    ],\n",
    "    dtype=np.uint64,\n",
    ")\n",
    "values = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float64)\n",
    "sizes = np.array([4, 4], dtype=np.uint64)\n",
    "sparsity = np.array([False, True], dtype=np.bool8)\n",
    "\n",
    "B_csr = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)\n",
    "B = engine.convert_csr_to_csc(B_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "849c050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [0, 2],\n",
    "        [1, 1],\n",
    "        [1, 2],\n",
    "        [2, 1],\n",
    "        [2, 2],\n",
    "        [3, 1],\n",
    "        [3, 2],\n",
    "    ],\n",
    "    dtype=np.uint64,\n",
    ")\n",
    "values = np.array([-0.1, 0.2, -0.3, 0.4, -0.5, 0.6, -0.7, 0.8], dtype=np.float64)\n",
    "sizes = np.array([4, 4], dtype=np.uint64)\n",
    "sparsity = np.array([False, True], dtype=np.bool8)\n",
    "\n",
    "mask = mlir_graphblas.sparse_utils.MLIRSparseTensor(indices, values, sizes, sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea20554",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dense = engine.csr_densify4x4(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c190a36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 2.],\n",
       "       [3., 0., 0., 0.],\n",
       "       [4., 5., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0169161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_dense = engine.csc_densify4x4(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df49b6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 2.],\n",
       "       [0., 3., 0., 4.],\n",
       "       [5., 0., 6., 0.],\n",
       "       [7., 0., 8., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e25ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dense = engine.csr_densify4x4(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08a016c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. , -0.1,  0.2,  0. ],\n",
       "       [ 0. , -0.3,  0.4,  0. ],\n",
       "       [ 0. , -0.5,  0.6,  0. ],\n",
       "       [ 0. , -0.7,  0.8,  0. ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e54ae",
   "metadata": {},
   "source": [
    "## graphblas.matrix_multiply_reduce_to_scalar (No Mask)\n",
    "\n",
    "We'll show how to use `graphblas.matrix_multiply_reduce_to_scalar` without a mask here. \n",
    "\n",
    "We'll have code for `graphblas.matrix_multiply_reduce_to_scalar` as well as `graphblas.matrix_multiply` and `graphblas.matrix_reduce_to_scalar` to demonstrate the expected behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e34f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "module {\n",
    "    \n",
    "    func @matrix_multiply_plus_times(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>) -> tensor<?x?xf64, #CSR64> {\n",
    "        %answer = graphblas.matrix_multiply %a, %b { semiring = \"plus_times\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to tensor<?x?xf64, #CSR64>\n",
    "        return %answer : tensor<?x?xf64, #CSR64>\n",
    "    }\n",
    "    \n",
    "    func @matrix_sum(%sparse_tensor: tensor<?x?xf64, #CSR64>) -> f64 {\n",
    "        %answer = graphblas.matrix_reduce_to_scalar %sparse_tensor { aggregator = \"sum\" } : tensor<?x?xf64, #CSR64> to f64\n",
    "        return %answer : f64\n",
    "    }\n",
    "    \n",
    "    func @matrix_multiply_plus_times_sum(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>) -> f64 {\n",
    "        %answer = graphblas.matrix_multiply_reduce_to_scalar %a, %b { semiring = \"plus_times\", aggregator = \"sum\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>) to f64\n",
    "        return %answer : f64\n",
    "    }\n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ff88069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix_multiply_plus_times', 'matrix_sum', 'matrix_multiply_plus_times_sum']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b401fa",
   "metadata": {},
   "source": [
    "Let's first get some results from `graphblas.matrix_multiply` and `graphblas.matrix_reduce_to_scalar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c09f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul_result = engine.matrix_multiply_plus_times(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e50f37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0.,  8.,  0.],\n",
       "       [14.,  0., 16.,  0.],\n",
       "       [ 0.,  3.,  0.,  6.],\n",
       "       [ 0., 19.,  0., 28.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.csr_densify4x4(matmul_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f04a1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_from_sequential = engine.matrix_sum(matmul_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02d48bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction_from_sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b847ae8",
   "metadata": {},
   "source": [
    "Let's verify that our use of `graphblas.matrix_multiply_reduce_to_scalar` gets the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "159cc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_from_combined = engine.matrix_multiply_plus_times_sum(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ab1e916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction_from_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06bbbed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction_from_combined == reduction_from_sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4785efc",
   "metadata": {},
   "source": [
    "## graphblas.matrix_multiply_reduce_to_scalar (With Mask)\n",
    "\n",
    "`graphblas.matrix_multiply_reduce_to_scalar` also takes an optional mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95e5a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlir_text = \"\"\"\n",
    "#CSR64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (i,j)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "#CSC64 = #sparse_tensor.encoding<{\n",
    "  dimLevelType = [ \"dense\", \"compressed\" ],\n",
    "  dimOrdering = affine_map<(i,j) -> (j,i)>,\n",
    "  pointerBitWidth = 64,\n",
    "  indexBitWidth = 64\n",
    "}>\n",
    "\n",
    "module {\n",
    "    \n",
    "    func @matrix_multiply_plus_times_mask(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>, %m: tensor<?x?xf64, #CSR64>) -> tensor<?x?xf64, #CSR64> {\n",
    "        %answer = graphblas.matrix_multiply %a, %b, %m { semiring = \"plus_times\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>, tensor<?x?xf64, #CSR64>) to tensor<?x?xf64, #CSR64>\n",
    "        return %answer : tensor<?x?xf64, #CSR64>\n",
    "    }\n",
    "    \n",
    "    func @matrix_multiply_plus_times_sum_mask(%a: tensor<?x?xf64, #CSR64>, %b: tensor<?x?xf64, #CSC64>, %m: tensor<?x?xf64, #CSR64>) -> f64 {\n",
    "        %answer = graphblas.matrix_multiply_reduce_to_scalar %a, %b, %m { semiring = \"plus_times\", aggregator = \"sum\" } : (tensor<?x?xf64, #CSR64>, tensor<?x?xf64, #CSC64>, tensor<?x?xf64, #CSR64>) to f64\n",
    "        return %answer : f64\n",
    "    }\n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0dce06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix_multiply_plus_times_mask', 'matrix_multiply_plus_times_sum_mask']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.add(mlir_text, passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6cf23",
   "metadata": {},
   "source": [
    "Let's verify that we get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cb45032",
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul_result = engine.matrix_multiply_plus_times_mask(A, B, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7434646b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  8.,  0.],\n",
       "       [ 0.,  0., 16.,  0.],\n",
       "       [ 0.,  3.,  0.,  0.],\n",
       "       [ 0., 19.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.csr_densify4x4(matmul_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b79274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_from_sequential = engine.matrix_sum(matmul_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb77159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction_from_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44195f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_from_combined = engine.matrix_multiply_plus_times_sum_mask(A, B, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e94c9986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction_from_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c41d5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction_from_combined == reduction_from_sequential"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
